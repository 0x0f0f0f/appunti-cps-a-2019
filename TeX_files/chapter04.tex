\chapter{Catene di Markov}

\section{Catene di Markov e Processi Stocastici}

\begin{defn}
	\textbf{Processi Stocastici}
	Spesso abbiamo bisogno di rappresentare quantit\`a incerte che cambiano nel tempo. Possiamo rappresentarle con famiglie di variabili aleatore indicizzate mediante un parametro, spesso corrispondente al ``tempo"

	Una famiglia di variabili aleatorie $ \left\{X_t\right\}_{t\in \mathcal{T}} $ dove $ \mathcal{T} \subseteq \R $ e che assumono tutte valori nello stesso insieme $ E $ \`e  detta \textbf{processo stocastico}. L'insieme $ E $ \`e  detto spazio degli stati del processo, mentre l'insieme $ \mathcal{T} $ \`e  detto insieme dei tempi. Considereremo sempre gli insiemi degli stati e dei tempi \textit{discreti} (numerabili) e molto spesso finiti. L'insieme dei tempi pu\`o  essere un intervallo $ \mathcal{T} = [0,T] $. Ad esempio, insiemi $ \mathcal{T} $ validi possono essere: $ \N, \Z, \{0, 1, 2, \hdots, n\}, \{t_1, t_2, \hdots, t_n\} $. Dato un processo stocastico $ \{X_t\}_{t \in \mathcal{T}} $ le variabili aleatorie $ X_t \in E $ sono dette marginali del processo. Le leggi delle marginali di due processi potrebbero coincidere, pur essendo i due processi molto diversi.

\end{defn}


\begin{exmp}\label{ex-fond}
Consideriamo le estrazioni da un urna contenente 10 palline rosse (R) e 3 palline blu (B). Prendiamo in considerazione il colore della pallina alla prima, seconda, terza, ecc. estrazione. Il fenomeno \`e  rappresentabile con una famiglia di variabili aleatorie.
	\begin{equation*}
	X_1, X_2, X_3, \hdots, X_n \in \{\text{rossa}, \text{blu}\}
	\end{equation*}
Considero tre tipi diversi di estrazione
\begin{enumerate}
\item estraggo senza reimbussolare
\item estraggo e reimbussolo la pallina estratta
\item estraggo la prima, estraggo la seconda e reimbussolo la prima, estraggo la terza e reimbussolo la
seconda, ecc. In pratica ad ogni estrazione nell'urna ci sono tutte le palline escluso l'ultima estratta
\end{enumerate}
Calcolare, nei tre casi, $\p{\text{3a estratta =R} | \text{1a estratta =B, 2a estratta=R} }$ nei tre casi.

Nel caso a) abbiamo  $\p{\text{3a =R} | \text{1a=B, 2a=R} }=\p{\text{3a =R}}=10/3$;

nel caso b)
 $\p{\text{3a =R} | \text{1a=B, 2a=R} }=9/11$;

 nel caso c)
 $\p{\text{3a =R} | \text{1a=B, 2a=R} }=\p{\text{3a =R} | \text{2a=R} }= 9/12 $
\end{exmp}

In tutti i tre casi ogni marginale $X_t$ si trova nello stesso modo:
 $$\p{X_t=R}=\frac{\text{palline rosse presenti nell'urna}}{\text{palline totali presenti nell'urna}}$$  ma la legge specifica ottenuta dipende dall'istante $t$ in cui si fa l'estrazione e - a seconda del tipo di processo - dalla storia delle estrazioni precedenti.

\begin{defn}
	\textbf{Processo di Markov:}
	Un processo aleatorio \`e detto di Markov  se l'evento all'istante $k+1$ dipende solo dall'esito dell'evento
	$k$ ma non da quelli precedenti. In formule, se $e_k$ rappresenta il valore assunto dalla variabile $X_k$, il processo $\{X_t\}_{t\in \N}$ \`e di Markov se
	$$\p{X_{k+1}=e_{k+1} | X_k=e_k\cap X_{k-1}=e_{k-1}\cap\dots\cap X_0=e_0}=\p{X_{k+1}=e_{k+1} | X_k=e_k}.
	$$
In altri termini si pu\`o anche dire
	\begin{quote}
		{Un processo \`e  di Markov se conoscendo il presente, passato e futuro sono indipendenti.}
	\end{quote}
\end{defn}
	\begin{exmp}
	Tornando all'esempio \ref{ex-fond} dell'estrazione dall'urna  un'estrazione con reimmissione \`e  sicuramente un processo di Markov, se l'estrazione \`e  senza reimmissione il processo \textbf{non} \`e  di Markov. Il motivo \`e  che tutta la sequenza di palline estratte \`e  necessaria per conoscere il contenuto esatto dell'urna (l'informazione passata non pu\`o  essere trascurata). Anche nel terzo caso si ha un processo di Markox, perch\'e le estrazioni non sono indipendenti tra di loro, ma ogni estrazione dipende solo dalla precedente.
\end{exmp}

\begin{note} Se un processo \`e di Markov per conoscerlo interamente bastano le probabilit\`a di
transizione $\p{X_{k+1}=j\ |\ X_{k}=i}$ (oltre alla marginale $X_0$).
\end{note}



\begin{defn}
	Un process di Markov $ {X_i}_{i\in \N} $ \`e  \textbf{omogeneo} se le probabilit\`a di transizione non dipendono dall'istante $k$, ovvero:
	\begin{equation*}
	\begin{aligned}
		\forall i,j \in \N\ ,\  \p{X_{k+1} = j \mid \{X_k = i\}} = \p{X_1 = j \mid  \{X_0 = i\}}
	\end{aligned}
	\end{equation*}
\end{defn}

\begin{exmp}
	Nell'esempio \ref{ex-fond}, a) e c) sono processi di Markov omogenei.
\end{exmp}

\begin{exmp}
	Modifichiamo l'esempoi  \ref{ex-fond} nel modo seguente: oltre a quanto detto, ad ogni estrazione 
	aggiungiamo una pallina nera nell'urna. Allora a) e c) restano processi di Markov, ma non sono 
	pi\`u omogenei
\end{exmp}

\begin{note} Se un processo \`e di Markov omogeneo per conoscerlo interamente bastano le probabilit\`a della prima transizione $\p{X_{1}=j\ |\ X_{0}=i}$ (oltre alla marginale $X_0$).
\end{note}

\begin{defn}
	\textbf{Matrice di Transizione:}
		Fissato un ordinamento degli stati di un processo di Markov omogeneo a stati finito, si definisce
		Matrice di transizione la matrice $Q=(q_ij)_{ij}$ dove
		\begin{equation*}
		 Q_{ij} = Q_{i \to j} := \p{X_1 = j \mid I \cap \{X_0 = i\}}
		\end{equation*}
Questa definizione ci permette di collezionare le probabilit\`a di transizione in una singola matrice.
\end{defn}

\begin{defn}
	\textbf{Catena di Markov}:
	Un processo di Markov omogeneo $ \{X_i\}_{i=0,\hdots,n} $ a stati finiti (o discreti) \`e  detto \textbf{Catena di Markov}.
\end{defn}
	Si possono visualizzare le Catene di Markov, data una matrice di transizione, con un grafo orientato analogo agli automi a stati finiti.
	Ad ogni stato $ i \in E $ facciamo corrispondere un nodo, e ad ogni probabilit\`a di transizione 
	$ Q_{i \to j} $ strettamente positiva facciamo corrispondere un arco $ (i, j) $. Non si disegnano gli archi delle probabilit\`a di transizione nulle. La rappresentazione con i grafi non indica nulla sulle leggi marginali della catena.

\begin{exmp}
Scriviamo la matrice di transizione per l'esempio \ref{ex-fond} nei casi a) e c).
Se associamo al rosso lo stato 1 e al blu lo stato 2
abbiamo
\begin{eqnarray*}
	\text{a): }Q = \begin{pmatrix}
	10/13 & 3/13 \\
	10/13 & 3/13
	\end{pmatrix}
		&&
	\text{c): }Q = \begin{pmatrix}
	9/12 & 3/12 \\
	10/12 & 2/12
	\end{pmatrix}
\end{eqnarray*}
Si noti che la somma delle righe della matrice deve dare 1 (rappresenta una densit\`a di probabilit\`a).
\end{exmp}

\begin{exmp}
Scriviamo per l'esempio \ref{ex-fond} nel caso c), il grafo associato alla catena di Markov
	\begin{figure}[H]
		\centering
		\caption{Catena di Markov}
		\begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node distance=3.5cm]
		
		\node[state] (A)                    {Rossa};
		\node[state] (B) [right of=A] 	   	{Blu};
		
		\path 	(A)		edge [bend left]  	node {3/12} 		(B)
						edge [loop left] 	node {9/12} 		(A)
		(B)				edge [bend left]  	node {10/12} 		(A)
						edge [loop right] 	node {2/12} 		(B);

		\end{tikzpicture}
	\end{figure}
Si noti che in questo caso la somma dei valori {\em uscenti} da un nodo deve dare 1.
\end{exmp}



\begin{exmp}
	All'interno di una CPU abbiamo due stati, \textbf{busy} (nodo 1) e \textbf{free} (nodo 2).

	\begin{equation*}
	Q = \begin{pmatrix}
	0,3 & 0,7 \\
	0,2 & 0,8
	\end{pmatrix}
	\end{equation*}
	
	\begin{figure}[H]
		\centering
		\caption{Catena di Markov}
		\begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node distance=3.5cm]
		
		\node[state] (A)                    {Busy};
		\node[state] (B) [right of=A] 	   	{Free};
		
		\path 	(A)		edge [bend left]  	node {0.7} 		(B)
						edge [loop left] 	node {0.3} 		(A)
				(B)		edge [bend left]  	node {0.2} 		(A)
						edge [loop right] 	node {0.8} 		(B);
				
		\end{tikzpicture}
	\end{figure}
\end{exmp}


\section{Calcolo Algebrico su catene di Markov}

\begin{prop}\textbf{Calcolo del Marginale di una Catena di Markov}
Sia data la distribuzione di probabilit\`a di trovarsi in uno stato iniziale $ \p{X_0 = j}$ $\forall j $. 
Definiamo il vettore riga $ v = (\p{X_0 = j})_j $. Sia $ Q=(q_{ji})_{ji} $ la matrice di transizione associata 
ad una catena di Markov, ovvero $ q_{ji} =q_{j \to i}= \p{X_1 = i \mid X_0 = j} $. 

Allora possiamo calcolare la legge marginale  $ \p{X_k = i} $ come:
 $$ \p{X_k = i} = (v \cdot Q^k)_i = (v \cdot  Q \cdot Q \cdot \hdots \cdot Q)_i.$$
 \end{prop}
 \begin{proof}
Dimostriamo  per induzione. Per $k=1$ abbiamo
\begin{equation*}
	\begin{aligned}
	\p{X_1 = i} =  \sum_j (\p{X_1 = i \mid X_0 = j}) \p{ X_0 = j}= \\
	 = \sum_j q_{j \to i} v_j = \sum_j v_j q_{j \to i} = (v \cdot Q)_i.
	\end{aligned}
\end{equation*}
Nel passo induttivo, supponiamo di conoscere la $k$-esima marginale $(\p{X_1 = j} )_j$, che indico 
per comodit\`a con il vettore $v^k=(\p{X_1 = j} )_j$, e che, per ipotesi induttiva valga $v_k=v\cdot Q^k$.
Allora per la $(k+1)$-esima marginale abbiamo
\begin{equation*}
	\begin{aligned}
	\p{X_{k+1} = i} =  \sum_j (\p{X_{k+1} = i \mid X_{k}= j}) \p{ X_{k} = j}= \\
	 = \sum_j q_{j \to i} v^k_j = \sum_j v^k_j q_{j \to i} = (v^k \cdot Q)_i=(v\cdot Q^k \cdot Q)_i=
	  (v\cdot Q^{k+1} )_i
	\end{aligned}
\end{equation*}

\end{proof} 

A volte, conosciamo con certezza lo stato iniziale di un sistema, ad esempio sappiamo con sicurezza 
che $ X_0 = j$. In quel caso il vettore iniziale \`e dato da $v =  e_j =\{0, 0, 0, \hdots, 0, 1, \hdots, 0, 0,\} $  
dove l'unico valore 1 \`e  in posizione $j$-esima). In quel caso per il calcolo della $k$-esima marginale si ha
$
\p{X_k = j \mid X_0 = i}=(e_i Q^k)_j = (Q^k)_{ij}. 
$

Allora anche l'insieme delle $ (Q^k)_{ij}$ al variare di $j$ \`e una densit\`a di probabilit\`a e quindi deve valere
$\sum_i (Q^k)_{ij}=1$ per ogni $j$.
\begin{exmp}\label{ex-inv}
	Riprendendo l'esempio \ref{ex-fond}, caso c):
	
	\begin{equation*}
	\begin{aligned}
	Q=\begin{pmatrix}
	\frac{9}{12} & \frac{3}{12} \\
	&\\
	\frac{10}{12} & \frac{2}{12}
	\end{pmatrix}
	\end{aligned}
	\end{equation*}
	
	Distribuzione di $ X_0 $: $ v = (\frac{10}{13}, \frac{3}{13}) $.
	
	Marginale $ X_1 $: $ v \cdot Q = (\frac{10}{13}, \frac{3}{13})\begin{pmatrix}
	\frac{9}{12} & \frac{3}{12} \\
	&\\
	\frac{10}{12} & \frac{2}{12}
	\end{pmatrix} $ = $ (\frac{120}{13 \cdot 12}, \frac{36}{13 \cdot 12}) = \left( \frac{10}{13}, \frac{3}{13} \right)$
	
	Si ha che $ \p{X_{10} = B} = (v \cdot Q^{10})_2= ((v \cdot Q) Q^9)_2 = (v \cdot Q^9)_2 =
	\dots=(v)_2 ={\dfrac{3}{13}} $
	
\end{exmp}

\paragraph{Calcolo dei valori attesi}

Data $ (X)_k $una Catena di Markov. $ Q $ matrice di transizione, $ f : \R \to \R$ funzione reale, voglio calcolare $ \E{f(X_k) \mid X_0 = i} $ (ovvero so che all'istante $X_0$ il sistema si trova nello stato $i$).

Prendiamo ad esempio il caso $ k = 1 $

\begin{equation*}
	\begin{aligned}
	\E{f(X_1)} \mid X_0 = i) = \sum_j f(j) \cdot \p{X_1 = j \mid X_0 = i} \\
	= \sum_j f(j) \cdot q_{ij} = \sum_j \cdot q_{ij}  f(j)= (Q \cdot f)_i \\
	\text{dove }\vec{f} = (f(j))_j
	\end{aligned}
\end{equation*}

\begin{prop}
In generale si ha che 
$$\E{f(X_k) \mid X_0 = i} = (Q^k\cdot \vec{f})_i $$

Se non conosco con certezza lo stato iniziale allora indichiamo, come prima, $ (P(X_0) =i)_i = v) $
e vale
\begin{equation*}
\E{f(X_k \mid X_0)} =v\cdot Q^k \cdot \vec{f}
\end{equation*}
(con $(X_k \mid X_0) $ si intende la $k$-esima marginale conoscendo la distribuzione di probabilit\`a iniziale, 
mentre con $(X_k \mid X_0=i) $ si intende la $k$-esima marginale sapendo che lo stato 
iniziale vale con certezza $i$
\end{prop}
La dimostrazione \`e simile alla dimostrazione precedente, e quindi la omettiamo.

D'ora in poi indicheremo semplicemente con $f$ il vettore $\vec{f}$, per alleggerire la notazione.


\begin{exrc} 
Prendiamo ancora l'esempio \ref{ex-fond}, caso c), e scommettiamo nel seguente modo:
se esce una pallina rossa perdo 1 euro. Se esce la blu guadagno 5 euro. Diciamo che scommettiamo sulla 
seconda estrazione. Vediamo se conviene giocare nel caso in cui sappiamo che alla prima estrazione \`e 
uscita una pallina rossa, e nel caso in cui non conosciamo la prima estrazione. 
Dobbiamo quindi calcolare, rispettivamente  $\E{f(X_1) \mid X_0 = R}$ e  $\E{f(X_1) \mid X_0 }$
Il vettore $f$ sar\`a $f=(-1,5)$, calcoliamo intanto 
	\begin{equation*}
		Q\cdot {f} = \begin{pmatrix}
	\dfrac{9}{12} & \dfrac{3}{12} \\
	&\\
	\dfrac{10}{12} & \dfrac{2}{12}
	\end{pmatrix} \begin{pmatrix}
	-1 \\ 5
	\end{pmatrix} = \begin{pmatrix}
	1/2 \\ 0
	\end{pmatrix} 	
	\end{equation*}
Quindi nel caso in cui $X_0=R$ il vettore iniziale \`e $v=(1,0)$, quindi 
  $\E{f(X_1) \mid X_0 = R}=(1,0)\cdot Q\cdot {f} =1/2$, mentre se non si conosce il risultato della prima estrazione il vettore iniziale \`e $v=(10/13,3/13)$, quindi abbiamo 
   $\E{f(X_1) \mid X_0 = R}=(10/13,3/13)\cdot Q\cdot {f} =10/26$.
  \end{exrc}


\paragraph{Catene stazionarie e stati di equilbrio}

\`E importante lo studio degli equilibri di un sistema, ovvero degli stati per cui il sistema non varia nel tempo 
(e, in certe condizioni, a cui il sistema tende nel tempo anche se si parte da uno stato che non \`e di equilibrio)
Per le catene di Markov la ricerca di questi stati non \`e difficile. 

\begin{defn}
	\textbf{Distribuzione invariante}
	Sia data una catena di Markov omogenea, con  matrice di transizione $ Q $. 
	La \textbf{distribuzione invariante} 
	per tale catena \`e  un vettore $ {\mu} = (\mu_i)_i $ tale che 	
	\begin{equation*}
	\begin{cases}
	\mu_i \geq 0 \\
	\sum_i \mu_i = 1 \\
	\vec{\mu} \cdot Q = \vec{\mu} \\
	\end{cases}
	\end{equation*}
	\end{defn}
\begin{note}
Si osservi che $ {\mu}^\tau $ \`e  l'autovettore di $ Q^\tau$riferito all'autovalore 1,  quindi se una
distribuzione invariante per $Q$ esiste, basta risolvere $(Q^\tau-Id)\mu^\tau = 0$
\end{note}

\begin{defn}
	\textbf{Catena Stazionaria}
	
	Una Catena di Markov $(X_k)_k$ \`e  una \textbf{catena stazionaria} se \textbf{tutte} le sue marginali sono uguali, ovvero se $\p{X_k=i}=p{X_0=i}$ per ogni $i,k$.
	\end{defn}
	
 Se la catena  $(X_k)_k$ \`e  stazionaria, se prendiamo il vettore della prima marginale 
	 $\mu=(p{X_0=i})_i$ abbiamo che $\mu\cdot Q^k=\mu$ per ogni $k$. Ma allora 
	 $\mu=(p{X_0=i})_i$  \`e una distribuzione invariante per $Q$. Viceversa, se abbiamo una distribuzione
	 invariante $\mu$ per una certa catena di Markov con matrice di transizione $Q$, allora tale 
	 catena \`e stazionaria, infatti
	 $$
	 \mu\cdot Q^k=(\mu\cdot Q)\cdot Q^{k-1}=\mu\cdot Q^{k-1}=\dots=\mu\cdot Q=\mu.
 $$
Quindi 
$$ (X_k)_k \text {\`e una catena di Markov stazionaria} \Leftrightarrow (p{X_0=i})_i
 \text{ \`e una sua distribuzione invariante)}
$$	 

\begin{exmp} 
Abbiamo visto nell'esempio \ref{ex-inv} che il vettore $ \left( \frac{10}{13}, \frac{3}{13} \right)$ \`e una
distribuzione invariante per la catena di Markov dell'esempio \ref{ex-fond}, caso c). Siamo stati fortunati 
o questo processo \`e una catena invariante indipendentemente dal numero di biglie blu e rosse?

Supponiamo di avere quindi $ N = B + R$ biglie totali, di cui $R $ Rosse e $ B $ Blu. Il primo nodo sono le biglie rosse ed 
il secondo quelle blu, al solito.
Le probabilit\`a di transizione, e la matrice $Q$ saranno quindi 	
	\begin{equation*}
	\begin{aligned}
	q_{1,1} = \p{X_1 = R \mid X_0 = R} = \dfrac{R-1}{N-1} \\
	q_{1,2} = \p{X_1 = B \mid X_0 = R} = \dfrac{B}{N-1} \\
	q_{2,1} = \p{X_1 = R \mid X_0 = B} = \dfrac{R}{N-1} \\
	q_{2,2} = \p{X_1 = B \mid X_0 = B} = \dfrac{B-1}{N-1} \\
	Q = \begin{pmatrix}
	\dfrac{R-1}{N-1} & \dfrac{B}{N-1} \\
	&\\
	\dfrac{R}{N-1} & \dfrac{B-1}{N-1}
	\end{pmatrix}
	\end{aligned}
	\end{equation*}
	
	Verifichiamo che lo stato iniziale $ \mu = \left(\dfrac{R}{N}, \dfrac{B}{N}\right) $ \`e  una distribuzione invariante.
	
	\begin{equation*}
	\begin{aligned}
	\mu Q = \left(\dfrac{R}{N}, \dfrac{B}{N}\right)\begin{pmatrix}
	\dfrac{R-1}{N-1} & \dfrac{B}{N-1} \\
	&\\
	\dfrac{R}{N-1} & \dfrac{B-1}{N-1}
	\end{pmatrix} \\
	= \left(\dfrac{R(R+B-1)}{N(N-1)} , \dfrac{B(R+B-1)}{N(N-1)}\right) = \left(\dfrac{R}{N}, \dfrac{B}{N}\right)
	\end{aligned}
	\end{equation*}
\end{exmp}



\begin{defn}
	\textbf{Matrice di Transizione regolare}
	Una matrice di transizione $ Q $ si dice regolare se per qualche $k$  si ha che $(Q^k)_{ij} > 0 $.
	 \end{defn}
Se $ Q $ \`e  regolare e $ v $ \`e  uno stato iniziale qualsiasi allora $ v\cdot Q^k $ tende alla distribuzione invariante per la catena di 
Markov. Quindi, in questo caso, da qualsiasi stato iniziale si converge verso una distribuzione che possiamo calcolare a priori. 
Quindi il comportamento di questo sistema diventa prevedibile su tempi lunghi. 

\begin{exmp}
	All'interno di una CPU abbiamo due stati, \textbf{busy} (nodo 1) e \textbf{free} (nodo 2).
	
	\begin{equation*}
	Q = \begin{pmatrix}
	0,3 & 0,7 \\
	0,2 & 0,8
	\end{pmatrix}
	\end{equation*}
	
	Cerco $ \mu $ distribuzione invariante. Sappiamo che $ \mu $ \`e  autovettore di autovalore 1:
	
	\begin{equation*}
	\begin{aligned}
	\mu Q = \mu \iff Q^\tau \mu^\tau  = \mu^\tau \iff (Q^\tau -I)\mu^\tau = 0 \\
	Q^\tau - I = \begin{pmatrix}
	0.3 & 0.2 \\
	0.7 & 0.8
	\end{pmatrix} - \begin{pmatrix}
	1 & 0 \\ 0 & 1
	\end{pmatrix} = \begin{pmatrix}
	-0.7 & 0.2 \\
	0.7 & -0.2
	\end{pmatrix} \\
	\begin{pmatrix}
	-0.7 & 0.2 \\
	0.7 & -0.2
	\end{pmatrix} \begin{pmatrix}
	\mu_1 \\ \mu_2
	\end{pmatrix} = 0 
	\implies \begin{cases}
	-0.7\mu_1 + 0.2 \mu_2 = 0 \\
	0.7\mu_1 - 0.2 \mu_2 = 0 \\
	\mu_1 + \mu_2 = 1\\
	\mu_1 \geq 0; \mu_2 \geq 0	

	\end{cases}
	\end{aligned}
	\end{equation*}
	
Risolvendo il sistema si ottiene
$$
	\mu=\left( \dfrac{2}{9},\dfrac{7}{9}\right)
$$	
\end{exmp}

Si noti che la matrice di transizione dell'esercizio precedente \`e regolare. 
Quindi se partiamo da un qualsiasi stato, per tempi molto lunghi lo stato del sistema si avviciner\`a alla distribuzione invariante.
In altre parole, dopo abbastanza tempo la probabilit\`a di trovare la CPU occupata sar\`a circa di $2/9$, mentre 
la probabilit\`a di trovarla  occupata sar\`a circa di $7/9$.

\section{Esercizi}

\begin{exrc}
	\textbf{Passeggiata Aleatoria}
	Mi muovo nell'asse X casualmente partendo da 0. Al minuto $ k $ lancio una moneta. Se esce testa mi muovo a destra, se esce croce mi muovo a sinistra. Voglio ottenere la posizione al minuto k. Disegnare la catena di Markov come grafo.
	
	\begin{equation*}
	\begin{aligned}
	Y_k = \text{Bern}\left(\dfrac{1}{2}\right) \text{ (lancio della moneta)}\\
	Y_k \in \{-1, +1\} \\
	X_k = \text{posizione} \\
	\begin{cases}
	X_0 = 0 \\
	X_{k+1} = X_k + Y_k
	\end{cases}
	\end{aligned}
	\end{equation*}
	
	\begin{figure}[H]
		\centering
		\caption{Catena di Markov della passeggiata aleatoria}
		\begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node distance=2cm]
		
		\node[state] (A)                    {0};
		\node[state] (B) [right of=A] 	   	{1};
		\node[state] (C) [right of=B] 	   	{2};
		\node[state] (D) [right of=C] 	   	{$ \hdots $};
		\node[state] (E) [left of=A] 	   	{-1};
		\node[state] (F) [left of=E] 	   	{-2};
		\node[state] (G) [left of=F] 	   	{$ \hdots $};		
		;
		
		\path 	
		(A)		edge [bend left]  	node {1/2} 		(B)
				edge [bend left]  	node {1/2} 		(E)
		(B)		edge [bend left]  	node {1/2} 		(C)
				edge [bend left]  	node {1/2} 		(A)
		(C)     edge [bend left]  	node {1/2} 		(D)
				edge [bend left]  	node {1/2} 		(B)
		(E)		edge [bend left]	node {1/2}		(F)
				edge [bend left]  	node {1/2} 		(A)
		(F)		edge [bend left]  	node {1/2} 		(G)
				edge [bend left]  	node {1/2} 		(E);
		\end{tikzpicture}
	\end{figure}
\end{exrc}


\begin{exrc}
	Invece di prendere una passeggiata aleatoria, immaginiamo di voler 
	schematizzare una passeggiata di un ubriaco che si muove senza meta, quindi in modo aleatorio, ma 
	che \`e  restio a cambiare direzione.
	Quindi se all'istante $ k $ \`e  andato a sinistra, all'istante $ k+1 $ la direzione sinistra sar\`a  pi\`u  probabile della destra. La sua posizione \`e  una catena di Markov? 
	
	No, perch\'e  dipende dalla posizione all'istante precedente e dalla direzione. La scelta di andare a destra o sinistra, invece, pu\`o essere rappresentata da una Catena di Markov, perch\'e  dipende soltanto dall'ultima scelta fatta.
\end{exrc}



\begin{exrc}
	
	Vogliamo simulare un essere vivente elementare con un automa. I suoi stati sono (1) \textbf{relax}, (2) \textbf{vigile}, (3) \textbf{fuga}, (4) \textbf{attacca}. Sappiamo che in presenza di qualche segnale esterno dallo stato di relax l'animale passa
	allo stato vigile, da qui pu\`o tornare allo stato di relax (con probabilit\`a $1/2$), oppure decidere di attaccare 
	(con probabilit\`a $1/5$) o fuggire (con probabilit\`a $3/10$). Scrivere il grafo e la matrice di transizione legata a questo processo.
	
Questo modello non \`e del tutto soddisfacente, perch\`e, ad esempio, il nostro automa uscir\`a dallo stato di relax a intervalli prestabiliti. 
In natura invece il cambiamento di stato di un animale dipende dagli stimoli esterni, che non sono ad intervalli regolari. 
Una maniera di introdurre quindi un tempo in una catena di Markov che non coincida necessariamente con gli intervalli a cui 
si studia il processo, si pu\`o introdurre per ogni stato $i$ una probabilit\`a $p_i$ che lo stato vada in se stesso. Provare a scrivere 
la matrice di transizione per l'automa cos\`\i\ modificato.
	
	\begin{figure}[H]
		\centering
		\caption{Catena di Markov dell'automa cellulare}
		\begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node distance=3.5cm]
		
		\node[state] 	(A)                    {R};
		\node[state]         	(B) [right of=A] 	   {V};
		\node[state]         	(C) [below right of=B] 	   {F};
		\node[state]         	(D) [above of=B] 	   {A};
		
		\path 	(A)		edge [bend left]  	node {1} 		(B)
		(B)
		edge [bend left] 	node {$\dfrac{1}{2}$} 		(A)
		edge [bend left]  	node {$\dfrac{1}{5}$} 		(D)
		edge [bend left]  	node {$\dfrac{3}{10}$} 		(C)
		(C)		edge [bend left]  	node {1} 		(B)
		(D)		edge [bend left]  	node {1} 		(B);
		\end{tikzpicture}
	\end{figure}
	
	\begin{equation*}
	\begin{aligned}
	Q = \begin{pmatrix}
	0 & 1 & 0 & 0 \\
	\dfrac{1}{2} & 0 & \dfrac{3}{10} & \dfrac{1}{5} \\
	0 & 1 & 0 & 0 \\
	0 & 1 & 0 & 0 
	\end{pmatrix}
	\end{aligned} 
	\end{equation*}
	
	\begin{figure}[H]
		\centering
		\caption{Catena di Markov dell'automa cellulare con tempo}
		\begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node distance=3.5cm]
		
		\node[state] 	(A)                    {R};
		\node[state]      (B) [right of=A] 	   {V};
		\node[state]      (C) [below right of=B] 	   {F};
		\node[state]      (D) [above of=B] 	   {A};
		
		\path 	(A) edge [bend left]  	node {$1-p_1$} (B) 
		edge [loop left] node {$p_1$} (A)
		(B) edge [loop left] node {$p_2$} 
		(C) edge [bend left] node {$ \dfrac{1}{2} (1-p_2) $} 		
		(A) edge [bend left]  	node {$\dfrac{1}{5}(1-p_2)$} 		
		(D)
		edge [bend left]  	node {$\dfrac{3}{10}(1-p_2)$} 		(C)
		(C)		edge [bend left]  	node {$1-p_3$} 		(B)
		edge [loop right] node {$p_3$} (C)
		(D)		edge [bend left]  	node {$1-p_4$} 		(B)
		 edge [loop right] node {$p_4$} (D);
		\end{tikzpicture}
	\end{figure}
\end{exrc}


\begin{exrc}


Abbiamo una CPU con 3 stati: (1) \textbf{Off}, (2) \textbf{Stand By}, (3) \textbf{Busy}

\begin{figure}[H]
	\centering
	\caption{Catena di Markov della CPU a 3 stati}
	\begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node distance=3.5cm]
	
	\node[state] 			(A)                    {O};
	\node[state]         	(B) [right of=A] 	   {S};
	\node[state]         	(C) [right of=B] 	   {B};
	
	\path 	(A)		edge [bend left]  	node {?} 		(B)
	edge [loop below] node {?} (A)
	(B)
	edge [loop below] node {0.4} (B)
	edge [bend left] 	node {?} 		(A)
	edge [bend left]  	node {0.2} 		(C)
	(C)		edge [bend left]  	node {0.6} 		(B)
	edge [loop below] node {0.4} (C);
	\end{tikzpicture}
\end{figure}


\begin{enumerate}
	\item Completare gli archi del grafo. Si possono completare sapendo che la somma degli archi uscenti da un nodo dev'essere 1.
	La matrice $Q$ sar\`a 
	$$Q = \begin{pmatrix}
		0.8 & 0.2 & 0 \\
		0.2 & 0.4 & 0.4 \\
		0 & 0.6 & 0.4
		\end{pmatrix} $$
	\item Calcolare $ \p{X_1 = O \mid X_0 = O} $ e $ \p{X_2 = O \mid X_0 = O} $. Abbiamo
	$\p{X_1 = O \mid X_0 = O}= q_{00} = 0.8 $. Calcoliamo ora $\p{X_2 = O \mid X_0 = O}$. Il vettore corrispondente 
	allo stato iniziale $X_0 = O$ \`e $v=(1,0,0)$, quindi 
	\begin{equation*}
				\p{X_2 = O \mid X_0=O} = (v \cdot Q \cdot Q)_1 = (0.68, \cdots, \cdots)_1=0.68
					\end{equation*}

	\item Supponiamo di avere una funzione costo tale che $c(O)=0$,  $c(S)=5$ e $c(B)=10$. Calcolare $ \E{c(X_k) \mid X_0 = O} $ per $ k = 1,2 $.
	Per $ k = 1 $ possiamo procedere in modo elementare  
	\begin{equation*}
		\begin{aligned}
		\E{c(X_1) \mid X_0 = O} = 0 \cdot \p{X_1 = O \mid X_0 = O } \\
		+ 5 \cdot \p{X_1 = S \mid X_0 = O} + 10 \cdot \p{X_1 = B \mid X_0 = O} \\
		= 5 \cdot \p{X_1 = S \mid X_0 = O} = 5 \cdot 0.2 = 1 
		\end{aligned}
	\end{equation*}
	Per $ k = 2 $ invece conviene usare la formula vista precedentemente. Il vettore associato al costo \`e $f = (0, 5, 10)$ quindi
	\begin{equation*}
			\E{c(X_2) \mid X_0 = O} = (Q^2 \cdot f)_1 = v\cdot Q^2\cdot f =  2
	\end{equation*}
	\item Calcolare la varianza $\var{c(X_1) \mid X_0 = 0}$. 
	Abbiamo
	\begin{equation*}
		\begin{aligned}
				c^2=(0, 25, 100) \\
		\E{c^2(X_1 \mid X_0 = 0}) = 0 \cdot \p{X_1 = O \mid X_0 = O } \\
		+ 25 \cdot \p{X_1 = S \mid X_0 = O } + 100 \cdot \p{X_1 = B \mid X_0 = O } \\ 
		= 25 \cdot 0.2 = 5
		\end{aligned}
	\end{equation*}
	quindi $$\var{c(X_1) \mid X_0 = 0} = 
		\E{c^2(X_1 \mid X_0 = 0)} - (\E{c(X_1) \mid X_0 = 0})^2 =5-1=4$$

	\item Calcolare $\mu$ distribuzione invariante e $\E{c(X_1) \mid \mu}$
\begin{equation*}
	\begin{aligned}
	(\text{Calcoliamo } \mu )\\ \\
	(Q^\tau - I) \mu^\tau = 0 \\
	\mu = (\mu_1, \mu_2, \mu_3) \\
	(Q^\tau - I)\mu^\tau = \begin{pmatrix}
	-0.2 & 0.2 & 0 \\ 
	0.2 & -0.6 & 0.6 \\
	0 & 0.4 & -0.6
	\end{pmatrix} \mu^\tau = 0 \\
	\implies \begin{cases}
	-0.2 \mu_1 + 0.2 \mu_2 = 0 \\
	0.2 \mu_1 - 0.6 \mu_2 + 0.6 \mu_3 = 0 \\
	 0.4 \mu_2 - 0.6 \mu_3 = 0 \\
	 \mu_1 + \mu_2 + \mu_3 = 1
	\end{cases} 
	\implies \begin{cases}
	\mu_1 = \mu_2 \\
	\mu_3 = \dfrac{2}{3} \mu_2 \\
 	\mu_1 + \mu_2 + \mu_3 = 1
	\end{cases} \\
	\implies \mu = \left(\dfrac{3}{8}, \dfrac{3}{8}, \dfrac{1}{4}\right) \\ \\
	(\text{Calcoliamo } \E{c(X_1) \mid \mu}) \\ \\
	\E{c(X_1) \mid \mu} = \mu \cdot Q \cdot f =4.375
		\end{aligned} 
\end{equation*}
\end{enumerate}
\end{exrc}

\begin{exrc}
	Dato il grafo di una Catena di Markov
	
	\FloatBarrier 
	\begin{figure}[H]
		\centering
		\caption{Catena di Markov}
		\begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node distance=3.5cm]
		
		\node[state] 			(A)                    {1};
		\node[state]         	(B) [below left of=A] 	   {2};
		\node[state]         	(C) [below right of=A] 	   {3};
		
		\path 	(A)		edge []  	node {0.5} 		(B)
		edge [loop above] node {0.5} (A)
		(B)
		edge []  	node {1} 		(C)
		(C) edge [] node {1} (A);
		\end{tikzpicture}
	\end{figure}

	\begin{enumerate}
		\item Trovare Q matrice di transizione 
		\begin{equation*}
		Q = \begin{pmatrix}
		0.5 & 0.5 & 0 \\
		0 & 0 & 1 \\ 
		1 & 0 & 0
		\end{pmatrix}
		\end{equation*}
		
		\item Scrivere le marginali $ X_1, X_2, X_3 $ sapendo che $ X_0 = 1 $
		
		\begin{equation*}
				\begin{aligned}
				v = (1, 0, 0) \\ 
				\p{X_1 \mid X_0 = 1} = v \cdot Q = \left(\dfrac{1}{2}, \dfrac{1}{2}, 0\right) \\
				\p{X_2 \mid X_0 = 1} = v \cdot Q^2 = \left(\dfrac{1}{2}, \dfrac{1}{2}, 0\right) Q = \left( \dfrac{1}{4}, \dfrac{1}{4}, \dfrac{1}{2} \right) \\
				\p{X_3 \mid X_0 = 1} = v \cdot Q^3 = \left(\dfrac{1}{2}, \dfrac{1}{2}, 0\right) Q^2 = \left(\dfrac{5}{8}, \dfrac{1}{8}, \dfrac{1}{4}\right)\\
				\end{aligned}
		\end{equation*}
	
		\item Calcolare la distribuzione invariante $ \mu $ e $ \E{\mu} $ 
		\begin{equation*}
			\begin{aligned}
			(Q^T-I)\mu^\tau = \begin{pmatrix}
			-0.5 & 0 & 1 \\
			0.5 & -1 & 0 \\
			0 & 1 & -1
			\end{pmatrix} \begin{pmatrix}
			\mu_1 \\ \mu_2 \\ \mu_3
			\end{pmatrix} \\
			\implies \begin{cases}
			- \mu_1 + 2\mu_3 = 0 \\ 
			\mu_1 - 2\mu_2 = 0 \\
			2\mu_2 - 2\mu_3 = 0
			\end{cases} \implies \begin{cases}
			\mu_1 = 2\mu_3 \\
			\mu_1 = 2\mu_2 \\
			\mu_1 + \mu_2 + \mu_3 = 1
			\end{cases} 
			\implies \mu = \left(\dfrac{1}{2}, \dfrac{1}{4}, \dfrac{1}{4}\right) \\ 
			\iff \begin{cases}
			\p{X_0 = 1} = \frac{1}{2} \\
			\p{X_0 = 2} = \frac{1}{4} \\
			\p{X_0 = 3} = \frac{1}{4} \\	
			\end{cases} \\
			\E{\mu} = 1 \cdot \p{X_0 = 1}  + 2 \cdot \p{X_0 = 2}  + 3 \cdot \p{X_0 =3 } =  1 \cdot \dfrac{1}{2} + 2 \cdot \dfrac{1}{4} + 3 \cdot \dfrac{1}{4} = \dfrac{7}{4}
			\end{aligned} 
		\end{equation*}
		
		\item Se la catena \`e  stazionaria calcolare $ \p{X_1 = 1 \mid X_3 = 1} $. Utilizziamo la formula di Bayes. 
		
		\begin{equation*}
			\begin{aligned}
			\p{X_1 = 1 \mid X_3 = 1} = \p{X_3 = 1 \mid X_1 = 1} \cdot \dfrac{\p{X_1 = 1}}{\p{X_3 = 1}} \\
			\text{La catena \`e  stazionaria: } \p{X_3 = 1} = \p{X_1 = 1} \\
			\implies \p{X_1 = 1 \mid X_3 = 1} = \p{X_3 = 1 \mid X_1 = 1} \\ 
			= \p{X_2 = 1 \mid X_0 = 1} = (1, 0, 0) Q^2 = \dfrac{1}{2}
			\end{aligned}
		\end{equation*}
	\end{enumerate}
\end{exrc}






