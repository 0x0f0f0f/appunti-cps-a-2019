\chapter{Catene di Markov}

\section{Catene di Markov e Processi Stocastici}

\begin{defn}
	\textbf{Processi Stocastici}
	Spesso abbiamo bisogno di rappresentare quantit\`a incerte che cambiano nel tempo. Possiamo rappresentarle con famiglie di variabili aleatore indicizzate mediante un parametro, spesso corrispondente al "tempo"
	
	Una famiglia di variabili aleatorie $ \left\{X_t\right\}_{t\in \mathcal{T}} $ dove $ \mathcal{T} \subseteq \R $ e che assumono tutte valori nello stesso insieme $ E $ \`e detta \textbf{processo stocastico}. L'insieme $ E $ \`e detto spazio degli stati del processo, mentre l'insieme $ \mathcal{T} $ \`e detto insieme dei tempi. Considereremo sempre gli insiemi degli stati e dei tempi \textit{discreti} (numerabili) e molto spesso finiti. L'insieme dei tempi pu\`o essere un intervallo $ \mathcal{T} = [0,T] $. Ad esempio, insiemi $ \mathcal{T} $ validi possono essere: $ \N, \Z, \{0, 1, 2, \hdots, n\}, \{t_1, t_2, \hdots, t_n\} $. Dato un processo stocastico $ \{X_t\}_{t \in \mathcal{T}} $ le variabili aleatorie $ X_t \in E $ sono dette marginali del processo. Le leggi delle marginali di due processi potrebbero coincidere, pur essendo i due processi molto diversi.
	
\end{defn}


\begin{exmp}
	
	Consideriamo le estrazioni da un urna contenente palline rosse e palline blu. Prendiamo in considerazione il colore della pallina alla prima, seconda, terza, ecc. estrazione. Il fenomeno \`e rappresentabile con una famiglia di variabili aleatorie.
	
	\begin{equation*}
	X_1, X_2, X_3, \hdots, X_n \in \{\text{rossa}, \text{blu}\}
	\end{equation*}
	
	I due processi cambiano radicalmente se le estrazioni sono con reimmissione della pallina o senza, ma sappiamo che le marginali hanno tutte le stesse leggi rispetto a $ \p{\cdot \mid \Omega} $
	
	\begin{equation*}
	\p{X_k = \text{rossa} \mid \Omega} = \dfrac{\text{\# palline rosse}}{\text{\# palline totali}}
	\end{equation*}
	
\end{exmp}

\begin{exmp}
	Assumiamo che le variabili $ X_1, \hdots, X_n \in \{\text{rossa}, \text{blu}\} $ siano tutte indipendenti (rispetto a $ \Omega $). Supponiamo di conoscere il numero di palline totali ed il numero di palline rosse inizialmente. Supponiamo di aver fatto $ k < n $ estrazioni e di conoscere il loro esito esatto. Poniamo ad esempio che siano state tutte rosse. Qual'\`e la probabilit\`a che all'estrazione $ k+1 $ otteniamo una pallina rossa?
	
	\begin{equation*}
	\begin{aligned}
	\p{X_{k+1} = rossa \mid \Omega \cap \{X_1 = \text{rossa}, \hdots, X_k = \text{rossa} \} } \\
	= P(X_{k+1} = \text{rossa} \mid \Omega)	\text{  (Per indipendenza)} \\
	= \dfrac{\text{\# palline rosse}}{\text{\# palline totali}}
	\end{aligned}
	\end{equation*}
	
	L'ipotesi di indipendenza probabilistica significa che non siamo capaci di "imparare" dal passato.
	
\end{exmp}

\begin{defn}
	\textbf{Propriet\`a di Markov:}
	Nei processi di Markov le informazioni ottenibili dal "passato" (la storia del processo fino al presente) possono essere utili a fare inferenza sullo stato futuro. In realt\`a costituiscono la classe pi\`u semplice in cui tutta la storia passata pu\`o essere trascurata ai fini di fare inferenza sul futuro.
	
	\begin{quote}
		\textbf{Un processo \`e di Markov se conoscendo il presente, passato e futuro sono indipendenti.}
	\end{quote}

	Dato un processo a tempi $ \mathcal{T} $ e stati $ E $ discreti. Un processo  $ \{X_{t_i}\}_{i=0, \hdots, n} $ con $ t_0 < t_1 < \hdots < t_n$ \`e detto \textbf{di Markov} (rispetto a $ \p{\cdot \mid I} $) se, presi qualunque $ k \in \{1, \hdots, n-1\} $ e $ A_0, A_i, A_{k+1} \subseteq E$ vale la seguente propriet\`a
	
	\begin{equation*}
		\begin{aligned}
		\p{X_{t_k+1} \in A_{k+1} \mid I \cap \{X_{t_k} \in A_k\} \cap \{X_{t_{k-1}} \in A_{k-1}\} \cap \{X_0 \in A_0\}} = \\
		= \p{X_{t_{k+1}} \in A_{k+1} \mid I \cap \{X_{t_k} \in A_k\}}
		\end{aligned}
	\end{equation*} 
	
	La propriet\`a di Markov permette di semplificare molto (ma non troppo) un modello probabilistico. L'indipendenza probabilistica va sempre considerata come un'ipotesi che introduciamo nel modello.
	
	Pi\`u in generale, una variabile aleatoria del processo $ X_{t_{k+1}} $ deve dipendere soltanto da $ X_{t_{k}} $. 
\end{defn}

\begin{note}
	Dato che $ E $ \`e un insieme discreto, si potrebbe dimostrare che \`e sufficiente verificare la proriet\`a di Markov su insiemi $ A_k $ costituiti da singoli punti $ A_k = \{i_k\} $, in modo tale che la condizione $ \{X_{t_k} \in A_k\} $ diventi $ \{X_{t_k} = i_k\} $
\end{note}

\begin{exmp}
	Tornando all'esempio dell'estrazione dall'urna (di cui conosciamo il contenuto), un'estrazione con reimmissione \`e sicuramente un processo di Markov, se l'estrazione \`e senza reimmissione il processo \textbf{non} \`e di Markov. Il motivo \`e che tutta la sequenza di palline estratte \`e necessaria per conoscere il contenuto esatto dell'urna (l'informazione passata non pu\`o essere trascurata).
\end{exmp}

\begin{exmp}
	Vediamo un esempio di processo di Markov basato dalle estrazioni dall'urna contenente $ R $ palline rosse e $ B $ palline blu ($ N = R+B $). Quando estraiamo la prima pallina, la teniamo all'esterno dell'urna. Successivamente estraiamo la seconda pallina, reinseriamo la prima pallina estratta e mescoliamo l'urna. Si procede poi tenendo fuori sempre l'ultima pallina estratta. Poniamo $ X_k = $ il colore della pallina estratta all'estrazione $ k $. La propriet\`a di Markov vale (l'informazione di tutta la sequenza di estrazioni non \`e rilevante eccetto l'ultima). Dati $ i,j \subseteq E $, le probabilit\`a di transizione
	\begin{equation*}
		\p{X_{t_{k+1}} = j \mid I \cap X_{t_k} = i}
	\end{equation*}
	
	potrebbero in generale dipendere da $ k $. Studieremo il caso in cui queste non dipendono da $ k $ per semplificare, e per semplificare ulteriormente assumiamo che $ t_k = k $.
\end{exmp}

\begin{defn}
	Un process di Markov $ {X_i}_{i=0,\hdots,n} $ \`e \textbf{omogeneo} se le probabilit\`a di transizione non dipendono da $ k \in \{0, 1, \hdots, n-1\} $, ovvero:
	\begin{equation*}
	\begin{aligned}
		\forall i,j \in E \> . \> \p{X_{k+1} = j \mid I \cap \{X_k = i\}} = \p{X_1 = j \mid I \cap \{X_0 = i\}}
	\end{aligned}
	\end{equation*}
\end{defn}

\begin{defn}
	\textbf{Matrice di Transizione:}
		Questa definizione ci permette di collezionare le probabilit\`a di transizione in una singola matrice di transizione
		
		\begin{equation*}
		\forall i,j \in E \> . \> Q_{ij} = Q_{i \to j} := \p{X_1 = j \mid I \cap \{X_0 = i\}}
		\end{equation*}
\end{defn}

\begin{note}
	Per scrivere una matrice di trasizione $ Q $ bisogna fissare un ordinamento degli stati $ E $. Una volta fissato questo ordinamento va seguito in tutto il problema.
	
	\begin{equation*}
	\sum_{j \in E} Q_{i \to j} = \sum_{j \in E} \p{X_1 = j \mid I \cap \{X_0 = i\}} = \p{X_1 \in E \mid I \cap \{X_0 = i\}} = 1
	\end{equation*}
\end{note}

\begin{defn}
	\textbf{Catena di Markov}:
	Un processo di Markov omogeneo $ \{X_i\}_{i=0,\hdots,n} $ a stati finiti (o discreti) \`e detto \textbf{Catena di Markov}.
	Si possono visualizzare le Catene di Markov, data una matrice di transizione, con un grafo orientato analogo agli automi a stati finiti.
	Ad ogni stato $ i \in E $ facciamo corrispondere un nodo, e ad ogni probabilit\`a di transizione $ Q_{i \to j} $ strettamente positiva facciamo corrispondere un arco $ (i, j) $. Non si disegnano gli archi delle probabilit\`a di transizione nulle. La rappresentazione con i grafi non indica nulla sulle leggi marginali della catena.
\end{defn}

\begin{exmp}
	All'interno di una CPU abbiamo due stati, \textbf{busy} (nodo 1) e \textbf{free} (nodo 2).
	
	\begin{equation*}
	Q = \begin{pmatrix}
	0,3 & 0,7 \\
	0,2 & 0,8
	\end{pmatrix}
	\end{equation*}
	
	\begin{figure}[H]
		\centering
		\caption{Catena di Markov}
		\begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node distance=3.5cm]
		
		\node[state] (A)                    {Busy};
		\node[state] (B) [right of=A] 	   	{Free};
		
		\path 	(A)		edge [bend left]  	node {0.7} 		(B)
						edge [loop left] 	node {0.3} 		(A)
				(B)		edge [bend left]  	node {0.2} 		(A)
						edge [loop right] 	node {0.8} 		(B);
				
		\end{tikzpicture}
	\end{figure}
\end{exmp}

\begin{exmp}
	Consideriamo un urna contenente $ R $ palline rosse e $ B $ palline blu, in tutto $ N = R + B $ palline. Effettuiamo estrazioni con reimmissione. Abbiamo gi\`a visto che la propriet\`a di Markov vale. Le probabilit\`a di transizione sono molto semplici da calcolare grazie all'indipendenza delle variabili $ \{X_k\} $.
	
	\begin{equation*}
		\begin{aligned}
			\p{X_{k+1} = \text{rossa} \mid \Omega \cap \{X_k = \text{rossa}\}} = \p{X_{k+1} = \text{rossa} \mid \Omega} = \dfrac{R}{N} \\
			\p{X_{k+1} = \text{blu} \mid \Omega \cap \{X_k = \text{rossa}\}} = \p{X_{k+1} = \text{blu} \mid \Omega} = \dfrac{B}{N} \\
			\p{X_{k+1} = \text{rossa} \mid \Omega \cap \{X_k = \text{blu}\}} = \p{X_{k+1} = \text{rossa} \mid \Omega} = \dfrac{R}{N} \\
			\p{X_{k+1} = \text{blu} \mid \Omega \cap \{X_k = \text{blu}\}} = \p{X_{k+1} = \text{blu} \mid \Omega} = \dfrac{B}{N} \\
		\end{aligned}
	\end{equation*}
	
	La catena di Markov sugli stati $ E = \{\text{rossa}, \text{blu}\} $ \`e omogenea con matrice di transizione.
	
	\begin{equation*}
	Q = \begin{pmatrix}
	R/N & B/N \\
	R/N & B/N
	\end{pmatrix}
	\end{equation*}
	
	\begin{figure}[H]
		\centering
		\caption{Catena di Markov}
		\begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node distance=3.5cm]
		
		\node[state] (A)                    {Rossa};
		\node[state] (B) [right of=A] 	   	{Blu};
		
		\path 	(A)		edge [bend left]  	node {B/N} 		(B)
						edge [loop left] 	node {R/N} 		(A)
		(B)				edge [bend left]  	node {R/N} 		(A)
						edge [loop right] 	node {B/N} 		(B);
		
		\end{tikzpicture}
	\end{figure}
\end{exmp}

\section{Calcolo Algebrico su catene di Markov}

\paragraph{Calcolo del Marginale di una Catena di Markov}
$ \p{X_0 = j} \forall j $ \`e un vettore che chiamiamo $ v = (\p{X_0 = j}) $, \`e lo stato iniziale. Definiamo $ Q(q_{ji}) $ matrice di transizione. $ q_{ji} = \p{X_1 = i \mid X_0 = j} $. Definiamo anche $ q_{j \to i} = \p{X_1 = i \mid X_0 = j} $. Ne otteniamo che $ \p{X_k = i} = (v \cdot Q^k)_i = (v_i = Q \cdot Q \cdot \hdots \cdot Q)_i $. Per correttezza, $ v \cdot Q $ \`e la legge di $ X_1 $. Calcoliamo $ X_1 $.

\begin{equation*}
	\begin{aligned}
	\p{X_1 = i} \cdot \sum_j (\p{X_1 = i \mid X_0 = j}) \\
	\p{X_1 = j} = \sum_j q_{j \to i} v_j = \sum_j v_j q_{j \to i} = (v \cdot Q_i)
	\end{aligned}
\end{equation*}


A volte, si pu\`o assegnare lo stato iniziale, ad esempio $ X_0 = j \iff v = \{0, 0, 0, \hdots, 0, 1, \hdots, 0, 0,\} = e_j $ (significa che vi \`e un 1 in posizione $ j $). Si ha che:

\begin{equation*}
(e_i Q^k) \cdot (\p{X_k = l \mid X_0 = i} ) = (e_i Q^k)_l = (Q^k)_{il}
\end{equation*}

\begin{exmp}
	Riprendendo l'esempio delle palline rosse e blu:
	
	\begin{equation*}
	\begin{aligned}
	Q=\begin{pmatrix}
	\frac{9}{12} & \frac{3}{12} \\
	\frac{10}{12} & \frac{2}{12}
	\end{pmatrix}
	\end{aligned}
	\end{equation*}
	
	Distribuzione di $ X_0 $: $ v = (\frac{10}{13}, \frac{3}{13}) $.
	
	Marginale $ X_1 $: $ v \cdot Q = (\frac{10}{13}, \frac{3}{13})\begin{pmatrix}
	\frac{9}{12} & \frac{3}{12} \\
	\frac{10}{12} & \frac{2}{12}
	\end{pmatrix} $ = $\hdots (\frac{120}{13 \cdot 12}, \frac{36}{13 \cdot 12}) = \left( \frac{10}{13}, \frac{3}{13} \right)$
	
	Si ha che $ \p{X_{10} = B} = (v \cdot Q^{10})_B = ((v \cdot Q) Q^9)_B = (v)_B = {\dfrac{3}{13}} $
	
\end{exmp}

\paragraph{Calcolo dei valori attesi}

Data $ (X)_k $una Catena di Markov. $ Q $ matrice di transizione, $ f : \R \to \R$ funzione reale, si ha che $ \E{f(X_k) \mid X_0 = i} $. Prendiamo il caso $ k = 1 $

\begin{equation*}
	\begin{aligned}
	\E{f(X_1} \mid X_0 = i) = \sum_j f(j) \cdot \p{x_1 = j \mid X_0 = i} \\
	= \sum_j f(j) \cdot q_{ij} = (Q \cdot f)_i \\
	\vec{f} = (f(j))_j
	\end{aligned}
\end{equation*}

Con $ k $ generico si ha $\E{f(X_k) \mid X_0 = i} = (Q^k \vec{f})_i $

Se non conosco lo stato iniziale devo conoscere la distribuzione $ (P(X_0) =i)_i = v) $

\begin{equation*}
\E{f(X_k \mid X_0} = \vec{f} Q^k v
\end{equation*}

% TODO riprendi esercizio
%\begin{exrc} 
%	Riprendendo l'esempio precedente, conviene giocare?
%	
%	
%	\begin{equation*}
%	\begin{aligned}
%	f(X_1 = R) = -1 \text{ Euro} \\
%	f(X_1 = B) = 1 \text{ Euro} \\
%	Q\vec{f} = \begin{pmatrix}
%	\dfrac{9}{12} & \dfrac{3}{12} \\
%	\dfrac{10}{12} & \dfrac{2}{12}
%	\end{pmatrix} \begin{pmatrix}
%	-1 \\ 5
%	\end{pmatrix} = \begin{pmatrix}
%	1/2 & 0
%	\end{pmatrix} \\
%	\E{f(X_1} \mid X_0 = R) = \dfrac{1}{2} \\
%	\E{f(X_1} \mid X_0 = B) = 0
%	\end{aligned}
%	\end{equation*}
%	
%	Se non si conosce il risultato della prima estrazione la speranza di vincita \`e $ \E{f(X_1} \mid X_0)  = \dfrac{1}{2} \cdot \p{X_0 = R} + 0 \cdot \p{X_0 = B} = \dfrac{1}{2} \cdot \dfrac{10}{13} = \dfrac{10}{26} $
%\end{exrc}



\begin{defn}
	\textbf{Distribuzione invariante}
	
	Cerchiamo di capire se uno stato di una catena di Markov \`e uno stato limite. La \textbf{distribuzione invariante} \`e un vettore $ \vec{\mu} = (\mu_i)_i $ per $ Q $ matrice di transizione se 
	
	\begin{equation*}
	\begin{cases}
	\mu_i \geq 0 \\
	\sum_i \mu_i = 1 \\
	\vec{mu} \cdot Q = \vec{\mu} \\
	\vec{mu}^T \cdot Q^T = \vec{\mu}^T \\
	\end{cases}
	\end{equation*}
	
	Ovvero $ \vec{mu}^T $ \`e l'autovettore dell'autovalore 1 per $ Q^T $
	
	Per trovare $ \mu^T $ si risolve $(Q^T-Id)\mu^T = 0$
\end{defn}

\begin{defn}
	\textbf{Catena Stazionaria}
	
	Una Catena di Markov $ (x_k)_k $ \`e una \textbf{catena stazionaria} se \textbf{tutte} le marginali sono uguali:
	
	\[ \begin{cases}
	\exists \mu \text{ distribuzione invariante} \\
	\mu Q^k = \mu \forall k 
	\end{cases} \]
	
	Ovvero se $ \p{X_0} = \p{X_1} = \hdots = \p{X_k} $
\end{defn}

\begin{defn}
	\textbf{Matrice di Transizione regolare}
	Una matrice di transizione $ Q $ si dice regolare se $ \forall k \>.\> (Q^k)_{ij} > 0 $. Se $ Q $ \`e regolare e $ v $ \`e uno stato iniziale qualsiasi allora $ vQ^k $ tende ad una qualche distribuzione limite e invariante.
\end{defn}


\section{Esercizi}

\begin{exrc}
	Ho un'urna con $ N = B + R$ biglie ($(2) B $ = Blu, $ (1) R $ = Rosse)
	
	\begin{equation*}
	\begin{aligned}
	q_{1,1} = \p{X_1 = R \mid X_0 = R} = \dfrac{R-1}{N-1} \\
	q_{1,2} = \p{X_1 = B \mid X_0 = R} = \dfrac{B}{N-1} \\
	q_{2,1} = \p{X_1 = R \mid X_0 = B} = \dfrac{R}{N-1} \\
	q_{2,2} = \p{X_1 = B \mid X_0 = B} = \dfrac{B-1}{N-1} \\
	Q = \begin{pmatrix}
	\dfrac{R-1}{N-1} & \dfrac{B}{N-1} \\
	\dfrac{R}{N-1} & \dfrac{B-1}{N-1}
	\end{pmatrix}
	\end{aligned}
	\end{equation*}
	
	Lo stato iniziale $ \mu = \left(\dfrac{R}{N}, \dfrac{B}{N}\right) $. Vogliamo sapere se $ \mu $ \`e invariante.
	
	\begin{equation*}
	\begin{aligned}
	\mu Q = \left(\dfrac{R}{N}, \dfrac{B}{N}\right)\begin{pmatrix}
	\dfrac{R-1}{N-1} & \dfrac{B}{N-1} \\
	\dfrac{R}{N-1} & \dfrac{B-1}{N-1}
	\end{pmatrix} \\
	= \left(\dfrac{R(R-1)}{N(N-1)} + \dfrac{RB}{N(N-1)}, \dfrac{B(R+B-1)}{N(N-1)}\right) = \left(\dfrac{R}{N}, \dfrac{B}{N}\right)
	\end{aligned}
	\end{equation*}
\end{exrc}

\begin{exrc}
	\textbf{Passeggiata Aleatoria}
	Mi muovo nell'asse X casualmente partendo da 0. Al minuto $ k $ lancio una moneta. Se esce testa mi muovo a destra, se esce croce mi muovo a sinistra. Voglio ottenere la posizione al minuto k.
	
	\begin{equation*}
	\begin{aligned}
	Y_k = \text{Bern}\left(\dfrac{1}{2}\right) \text{ (lancio della moneta)}\\
	Y_k \in \{-1, +1\} \\
	X_k = \text{posizione} \\
	\begin{cases}
	x_0 = 0 \\
	x_{k+1} = x_k + y_k
	\end{cases}
	\end{aligned}
	\end{equation*}
	
	\begin{figure}[H]
		\centering
		\caption{Catena di Markov della passeggiata aleatoria}
		\begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node distance=2cm]
		
		\node[state] (A)                    {0};
		\node[state] (B) [right of=A] 	   	{1};
		\node[state] (C) [right of=B] 	   	{2};
		\node[state] (D) [right of=C] 	   	{$ \hdots $};
		\node[state] (E) [left of=A] 	   	{-1};
		\node[state] (F) [left of=E] 	   	{-2};
		\node[state] (G) [left of=F] 	   	{$ \hdots $};		
		;
		
		\path 	
		(A)		edge [bend left]  	node {1/2} 		(B)
				edge [bend left]  	node {1/2} 		(E)
		(B)		edge [bend left]  	node {1/2} 		(C)
				edge [bend left]  	node {1/2} 		(A)
		(C)     edge [bend left]  	node {1/2} 		(D)
				edge [bend left]  	node {1/2} 		(B)
		(E)		edge [bend left]	node {1/2}		(F)
				edge [bend left]  	node {1/2} 		(A)
		(F)		edge [bend left]  	node {1/2} 		(G)
				edge [bend left]  	node {1/2} 		(E);
		\end{tikzpicture}
	\end{figure}
\end{exrc}


\begin{exrc}
	Un ubriaco \`e restio a cambiare direzione.
	Se al momento $ k $ \`e andato a sinistra, per $ k+1 $ la sinistra \`e pi\`u probabile della destra. La sua posizione \`e una catena di Markov? No, perch\'e dipende dalla posizione all'istante precedente e dalla direzione.
\end{exrc}

\begin{exrc}
	All'interno di una CPU abbiamo due stati, \textbf{busy} (nodo 1) e \textbf{free} (nodo 2).
	
	\begin{equation*}
	Q = \begin{pmatrix}
	0,3 & 0,7 \\
	0,2 & 0,8
	\end{pmatrix}
	\end{equation*}
	
	Cerco $ \mu $ distribuzione invariante. Sappiamo che $ \mu $ \`e autovettore di autovalore 1:
	
	\begin{equation*}
	\begin{aligned}
	\mu Q = \mu \iff \mu^T Q^T = \mu^T \iff (Q^T -I)\mu^T = 0 \\
	Q^T - I = \begin{pmatrix}
	0.3 & 0.2 \\
	0.7 & 0.8
	\end{pmatrix} - \begin{pmatrix}
	1 & 0 \\ 0 & 1
	\end{pmatrix} = \begin{pmatrix}
	-0.7 & 0.2 \\
	0.7 & -0.2
	\end{pmatrix} \\
	\begin{pmatrix}
	-0.7 & 0.2 \\
	0.7 & -0.2
	\end{pmatrix} \begin{pmatrix}
	\mu_1 \\ \mu_2
	\end{pmatrix} = 0 
	\implies \begin{cases}
	\mu_1 + \mu_2 = 1
	-0.7\mu_1 + 0.2 \mu_2 = 0 \\
	0.7\mu_1 - 0.2 \mu_2 = 0 \\
	\mu_1 \geq 0; \mu_2 \geq 0
	\end{cases} \\
	\text{(Risolvendo il sistema si ottiene)} \\
	\mu_1 = \dfrac{0.2}{0.9} = \dfrac{2}{9} \\
	\mu_2 = \dfrac{7}{9}
	\end{aligned}
	\end{equation*}
\end{exrc}

\begin{exrc}
	
	Vogliamo simulare un essere vivente elementare in un automa cellulare. I suoi stati sono (1) \textbf{relax}, (2) \textbf{vigile}, (3) \textbf{fuga}, (4) \textbf{attacca}
	
	\begin{figure}[H]
		\centering
		\caption{Catena di Markov dell'automa cellulare}
		\begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node distance=3.5cm]
		
		\node[state] 	(A)                    {R};
		\node[state]         	(B) [right of=A] 	   {V};
		\node[state]         	(C) [below right of=B] 	   {F};
		\node[state]         	(D) [above of=B] 	   {A};
		
		\path 	(A)		edge [bend left]  	node {1} 		(B)
		(B)
		edge [bend left] 	node {$\dfrac{1}{2}$} 		(A)
		edge [bend left]  	node {$\dfrac{1}{5}$} 		(D)
		edge [bend left]  	node {$\dfrac{3}{10}$} 		(C)
		(C)		edge [bend left]  	node {1} 		(B)
		(D)		edge [bend left]  	node {1} 		(B);
		\end{tikzpicture}
	\end{figure}
	
	\begin{equation*}
	\begin{aligned}
	Q = \begin{pmatrix}
	0 & 1 & 0 & 0 \\
	\dfrac{1}{2} & 0 & \dfrac{3}{10} & \dfrac{1}{5} \\
	0 & 1 & 0 & 0 \\
	0 & 1 & 0 & 0 
	\end{pmatrix}
	\end{aligned} 
	\end{equation*}
	
	\begin{figure}[H]
		\centering
		\caption{Catena di Markov dell'automa cellulare con tempo}
		\begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node distance=3.5cm]
		
		\node[state] 	(A)                    {R};
		\node[state]         	(B) [right of=A] 	   {V};
		\node[state]         	(C) [below right of=B] 	   {F};
		\node[state]         	(D) [above of=B] 	   {A};
		
		\path 	(A)		edge [bend left]  	node {1-P} 		(B)
		edge [loop left] node {$P_1$} (A)
		(B)
		edge [loop right] node {$P_2$} (B)
		edge [bend left] 	node {$ \dfrac{1}{2} (1-P_2) $} 		(A)
		edge [bend left]  	node {$\dfrac{1}{5}(1-P_2)$} 		(D)
		edge [bend left]  	node {$\dfrac{3}{10}(1-P_2)$} 		(C)
		(C)		edge [bend left]  	node {$1-P_3$} 		(B)
		edge [loop right] node {$P_3$} (C)
		(D)		edge [bend left]  	node {$1-P_4$} 		(B);
		\end{tikzpicture}
	\end{figure}
\end{exrc}


\begin{exrc}
	content
\end{exrc}

Abbiamo una CPU con 3 stati: (1) \textbf{Off}, (2) \textbf{Stand By}, (3) \textbf{Busy}

\begin{figure}[H]
	\centering
	\caption{Catena di Markov della CPU a 3 stati}
	\begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node distance=3.5cm]
	
	\node[state] 			(A)                    {O};
	\node[state]         	(B) [right of=A] 	   {S};
	\node[state]         	(C) [right of=B] 	   {B};
	
	\path 	(A)		edge [bend left]  	node {0.2} 		(B)
	edge [loop below] node {0.8} (A)
	(B)
	edge [loop below] node {0.4} (B)
	edge [bend left] 	node {0.2} 		(A)
	edge [bend left]  	node {0.4} 		(C)
	(C)		edge [bend left]  	node {0.6} 		(B)
	edge [loop below] node {0.4} (C);
	\end{tikzpicture}
\end{figure}


\begin{enumerate}
	\item Completare gli archi del grafo. Si possono completare sapendo che la somma degli archi uscenti da un nodo dev'essere 1.
	\item Calcolare $ \p{X_1 = O \mid X_0 = O} $ e $ \p{X_2 = O \mid X_0 = O} $. Abbiamo
	
	\begin{equation*}
		\begin{aligned}
		Q = \begin{pmatrix}
		0.8 & 0.2 & 0 \\
		0.2 & 0.4 & 0.4 \\
		0 & 0.6 & 0.4
		\end{pmatrix} \\
		q_{00} \to \p{X_1 = O \mid X_0 = O} = 0.8 \\
		\text{Calcoliamo ora } \p{X_2 = 0 \mid X_0 = 0} \\
		v = (1, 0, 0) \\
		v \cdot Q \cdot Q = (0.68, \hdots, \hdots) \text{ (Marginale della legge } X_2)
		\end{aligned} 
	\end{equation*}
	
	\item Trovare i costi $ c \to 0 $ per $ O $, $ c \to 5 $ per $ S $, $ c \to 10 $ per B. Calcolare $ \E{c(X_k) \mid X_0 = O} $ per $ k = 1,2 $.
	Per $ k = 1 $ si ha che 
	
	\begin{equation*}
		\begin{aligned}
		\E{c(X_1) \mid X_0 = O} = 0 \cdot \p{X_1 = O \mid X_0 = O } \\
		+ 5 \cdot \p{X_1 = S \mid X_0 = O} + 10 \cdot \p{X_1 = B \mid X_0 = O} \\
		= 5 \cdot \p{X_1 = S \mid X_0 = O} = 5 \cdot 0.2 = 1 
		\end{aligned}
	\end{equation*}

	Per $ k = 2 $ si ha che
	
	\begin{equation*}
		\begin{aligned} 
		f = (0, 5, 10) \\
		\E{c(X_2) \mid X_0 = O} = (Q^2 \cdot f)_1 = vQ^2f = \hdots = 2
		\end{aligned}
	\end{equation*}
	
	\item Calcolare la varianza 
	\begin{equation*}
		\begin{aligned}
		\var{c(X_1) \mid X_0 = 0} = \\
		\E{c^2(X_1 \mid X_0 = 0)} - (E{c(X_1) \mid X_0 = 0}) \\
		c^2=(0, 25, 100) \\
		\E{c^2(X_1 \mid X_0 = 0}) = 0 \cdot \p{X_1 = O \mid X_0 = O } \\
		+ 25 \cdot \p{X_1 = S \mid X_0 = O } + 100 \cdot \p{X_1 = B \mid X_0 = O } \\ 
		= 25 \cdot 0.2 = 5
		\end{aligned}
	\end{equation*}
	
	\item Calcolare $\mu$ distribuzione invariante e $\E{c(X_1) \mid \mu}$
\begin{equation*}
	\begin{aligned}
	(\text{Calcoliamo } \mu )\\ \\
	(Q^T - I) \mu^T = 0 \\
	\mu = (\mu_1, \mu_2, \mu_3) \\
	(Q^T - I)\mu^T = \begin{pmatrix}
	-0.2 & 0.2 & 0 \\ 
	0.2 & -0.6 & 0.6 \\
	0 & 0.4 & -0.6
	\end{pmatrix} \mu^T = 0 \\
	\implies \begin{cases}
	-0.2 \mu_1 + 0.2 \mu_2 = 0 \\
	0.2 \mu_1 - 0.6 \mu_2 + 0.6 \mu_3 = 0 \\
	 0.4 \mu_2 - 0.6 \mu_3 = 0 \\
	 \mu_1 + \mu_2 + \mu_3 = 1
	\end{cases} 
	\implies \begin{cases}
	\mu_1 = \mu_2 \\
	\mu_3 = \dfrac{2}{3} \mu_2 \\
 	\mu_1 + \mu_2 + \mu_3 = 1
	\end{cases} \\
	\implies \mu = \left(\dfrac{3}{8}, \dfrac{3}{8}, \dfrac{1}{4}\right) \\ \\
	(\text{Calcoliamo } \E{c(X_1) \mid \mu}) \\ \\
	\E{c(X_1) \mid \mu} = \mu \cdot Q \cdot f \\
	\text{(si pu\`o calcolare anche con) }
	\E{c(X_1) \mid \mu} =0 \cdot \p{X_1 = O \mid \mu} \\
	+ 5 \cdot \p{X_1 = S \mid \mu} + 10 \cdot \p{X_1 = B \mid \mu} \\
	\text{(Si prosegue per fattorizzazione)}
	\end{aligned} 
\end{equation*}
\end{enumerate}

\begin{exrc}
	Dato il grafo di una Catena di Markov
	
	\FloatBarrier 
	\begin{figure}[H]
		\centering
		\caption{Catena di Markov}
		\begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node distance=3.5cm]
		
		\node[state] 			(A)                    {1};
		\node[state]         	(B) [below left of=A] 	   {2};
		\node[state]         	(C) [below right of=A] 	   {3};
		
		\path 	(A)		edge []  	node {0.5} 		(B)
		edge [loop above] node {0.5} (A)
		(B)
		edge []  	node {1} 		(C)
		(C) edge [] node {1} (A);
		\end{tikzpicture}
	\end{figure}

	\begin{enumerate}
		\item Trovare Q matrice di transizione 
		\begin{equation*}
		Q = \begin{pmatrix}
		0.5 & 0.5 & 0 \\
		0 & 0 & 1 \\ 
		1 & 0 & 0
		\end{pmatrix}
		\end{equation*}
		
		\item Scrivere le marginali $ X_1, X_2, X_3 $ sapendo che $ X_0 = 1 $
		
		\begin{equation*}
				\begin{aligned}
				v = (1, 0, 0) \\ 
				\p{X_1 \mid X_0 = 1} = v \cdot Q = \left(\dfrac{1}{2}, \dfrac{1}{2}, 0\right) \\
				\p{X_2 \mid X_0 = 1} = v \cdot Q^2 = \left(\dfrac{1}{2}, \dfrac{1}{2}, 0\right) Q = \left( \dfrac{1}{4}, \dfrac{1}{4}, \dfrac{1}{2} \right) \\
				\p{X_3 \mid X_0 = 1} = v \cdot Q^3 = \left(\dfrac{1}{2}, \dfrac{1}{2}, 0\right) Q^2 = \left(\dfrac{5}{8}, \dfrac{1}{8}, \dfrac{1}{4}\right)\\
				\end{aligned}
		\end{equation*}
	
		\item Calcolare la distribuzione invariante $ \mu $ e $ \E{\mu} $ 
		\begin{equation*}
			\begin{aligned}
			(Q^T-I)\mu^T = \begin{pmatrix}
			-0.5 & 0 & 1 \\
			0.5 & -1 & 0 \\
			0 & 1 & -1
			\end{pmatrix} \begin{pmatrix}
			\mu_1 \\ \mu_2 \\ \mu_3
			\end{pmatrix} \\
			\implies \begin{cases}
			- \mu_1 + 2\mu_3 = 0 \\ 
			\mu_1 - 2\mu_2 = 0 \\
			2\mu_2 - 2\mu_3 = 0
			\end{cases} \implies \begin{cases}
			\mu_1 = 2\mu_3 \\
			\mu_1 = 2\mu_2 \\
			\mu_1 + \mu_2 + \mu_3 = 1
			\end{cases} 
			\implies \mu = \left(\dfrac{1}{2}, \dfrac{1}{4}, \dfrac{1}{4}\right) \\ 
			\iff \begin{cases}
			\p{X_0 = 1} = \frac{1}{2} \\
			\p{X_0 = 2} = \frac{1}{4} \\
			\p{X_0 = 3} = \frac{1}{4} \\	
			\end{cases} \\
			\E{\mu} = 1 \cdot \dfrac{1}{2} + 2 \cdot \dfrac{1}{4} + 3 \cdot \dfrac{1}{4} = \dfrac{7}{4}
			\end{aligned} 
		\end{equation*}
		
		\item Se la catena \`e stazionaria calcolare $ \p{X_1 = 1 \mid X_3 = 1} $. Utilizziamo la formula di Bayes. 
		
		\begin{equation*}
			\begin{aligned}
			\p{X_1 = 1 \mid X_3 = 1} = \p{X_3 = 1 \mid X_1 = 1} \cdot \dfrac{\p{X_1 = 1}}{\p{X_3 = 1}} \\
			\text{La catena \`e stazionaria: } \p{X_3 = 1} = \p{X_1 = 1} \\
			\implies \p{X_1 = 1 \mid X_3 = 1} = \p{X_3 = 1 \mid X_1 = 1} \\ 
			= \p{X_2 = 1 \mid X_0 = 1} = (1, 0, 0) Q^2 = \dfrac{1}{2}
			\end{aligned}
		\end{equation*}
	\end{enumerate}
\end{exrc}






